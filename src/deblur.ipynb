{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "%matplotlib inline  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import generateMotionBlurPSF\n",
    "import os\n",
    "class DataSource(object):\n",
    "    def __init__(self, imageSource, path='', length=[0,15], orientation=[0,180], filterCount=2000, minSize=100):\n",
    "        print('Generating filters.')\n",
    "        self.generateFilters(length, orientation, filterCount)\n",
    "        print('Generating filters --- DONE.')\n",
    "\n",
    "        self.minSize = minSize + self.filters[0].shape[2]\n",
    "        print('Reading images.')\n",
    "        self.readImages(imageSource, path, self.minSize)\n",
    "        print('Reading images --- DONE.')\n",
    "                \n",
    "        \n",
    "    def readImages(self, imageSource, path, minSize):\n",
    "        self.images = []\n",
    "        with open(imageSource, 'r') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                try:\n",
    "                    newImage = cv2.imread(os.path.join(path, line)).astype(np.float32)\n",
    "                    newImage /= 256.0\n",
    "                    newImage *= 0.8\n",
    "                    newImage += 0.1\n",
    "                    if len(newImage) == 2:\n",
    "                        newImage = np.expand_dims(newImage, axis=2)\n",
    "                        newImage = np.repeat(newImage, 3, axis = 2)\n",
    "                    if newImage.shape[0] > minSize and newImage.shape[1] > minSize:\n",
    "                        self.images.append(newImage.transpose(2,0,1))\n",
    "                    else:\n",
    "                        print('Warning: Image is too small \"{}\".'.format(line))\n",
    "                except:\n",
    "                    print('ERROR: While reading image \"{}\".'.format(line))\n",
    "\n",
    "                    \n",
    "    def generateFilters(self, length, orientation, filterCount):\n",
    "        self.filters = []\n",
    "        for i in range(filterCount):\n",
    "            #o = (orientation[1] - orientation[0]) * float(i) / filterCount # \n",
    "            o = (orientation[1] - orientation[0])* np.random.ranf() + orientation[0]\n",
    "            l = (length[1] - length[0]) * np.random.ranf() + length[0]\n",
    "            #l = length[1] #\n",
    "            psf = generateMotionBlurPSF(o, l)\n",
    "            border = int((length[1] - psf.shape[0]) / 2)\n",
    "            psf = np.pad(psf, [(border,border), (border,border)], mode='constant')\n",
    "            psf = np.expand_dims(psf, axis=0)\n",
    "            psf = np.repeat(psf, 3, axis = 0)\n",
    "            self.filters.append(psf)\n",
    "        self.filters = np.stack(self.filters, axis=0)\n",
    "        \n",
    "                    \n",
    "    def getBatch(self, count=32, cropSize=100):\n",
    "        \n",
    "        cropSize = cropSize + self.filters[0].shape[2]\n",
    "        \n",
    "        idx = np.random.choice(len(self.images), count)\n",
    "        images = [self.images[i] for i in idx]\n",
    "        outImages = []\n",
    "        for image in images:\n",
    "            i1 = np.random.randint(image.shape[1] - cropSize)\n",
    "            i2 = np.random.randint(image.shape[2] - cropSize)\n",
    "            outImages.append(image[:, i1:i1+cropSize, i2:i2+cropSize])\n",
    "        data = np.stack(outImages)\n",
    "        \n",
    "        idx = np.random.choice(self.filters.shape[0], count)\n",
    "        #idx = np.arange(self.filters.shape[0])\n",
    "        psf = self.filters[idx]\n",
    "        \n",
    "        return data, idx, psf\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filterCount=10000\n",
    "#del dataSource\n",
    "dataSource = DataSource(\n",
    "    '/home/ihradis/projects/2016-07-07_JPEG/data/skyscraper.15k', \n",
    "    '/home/ihradis/projects/2016-07-07_JPEG/data/',\n",
    "    minSize=150, length=[1,15], filterCount=filterCount) \n",
    "print(len(dataSource.images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import collage\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PsfNet(nn.Module):\n",
    "\n",
    "    def __init__(self, input_img, embeddingDim):\n",
    "        super(PsfNet, self).__init__()\n",
    "\n",
    "        self.filterSizes = [5, 3, 3]\n",
    "        self.filterCounts = [24, 48, 64]\n",
    "        self.strides = [1, 1]\n",
    "        self.fcSizes = [128, embeddingDim]\n",
    "        \n",
    "        lastChannels = input_img.data.shape[1]\n",
    "        self.convLayers = []\n",
    "        for fSize, fCount, stride in zip(self.filterSizes, self.filterCounts, self.strides):\n",
    "            self.convLayers.append(nn.Conv2d(in_channels=lastChannels, \n",
    "                                             out_channels=fCount, \n",
    "                                             kernel_size=fSize, \n",
    "                                             stride=stride))\n",
    "            lastChannels = fCount\n",
    "            self.convLayers.append(nn.BatchNorm2d(num_features=lastChannels, momentum=0.8))\n",
    "            self.convLayers.append(nn.ReLU())\n",
    "        \n",
    "        self.convLayers = nn.Sequential(*self.convLayers).cuda()\n",
    "        out = self.convLayers(input_img)\n",
    "        print('Conv output shape:', out.data.shape)\n",
    "        \n",
    "        lastChannels = out.data.shape[1]*out.data.shape[2]*out.data.shape[3]\n",
    "        self.fcLayers = []\n",
    "        for size in self.fcSizes[:-1]:\n",
    "            self.fcLayers.append(nn.Linear(lastChannels, size))\n",
    "            lastChannels = size\n",
    "            #self.fcLayers.append(nn.BatchNorm2d(num_features=lastChannels, momentum=0.3))\n",
    "            self.fcLayers.append(nn.ReLU())\n",
    "            \n",
    "        self.fcLayers.append(nn.Linear(lastChannels, self.fcSizes[-1]))\n",
    "        lastChannels = self.fcSizes[-1]\n",
    "           \n",
    "        self.fcLayers = nn.Sequential(*self.fcLayers).cuda()\n",
    "        \n",
    "        self.outBNorm = nn.BatchNorm1d(lastChannels, momentum=0.8)\n",
    "        \n",
    "    def forward(self, input_x):\n",
    "        x = input_x\n",
    "        x = self.convLayers(x)\n",
    "        x = x.view(x.data.shape[0], -1)\n",
    "        x = self.fcLayers(x)\n",
    "        x = F.normalize(x, p=2, dim=1, eps=1e-12)\n",
    "        x = self.outBNorm(x)\n",
    "        return x\n",
    "\n",
    "class LinearFilterNet(nn.Module):\n",
    "\n",
    "    def __init__(self, filterSizes, filterCounts):\n",
    "        super(LinearNet, self).__init__()\n",
    "\n",
    "        lastChannels = 3\n",
    "        self.layers = []\n",
    "        for fSize, fCount in zip(filterSizes, filterCounts):\n",
    "            self.layers.append(nn.Conv2d(lastChannels, fCount, fSize))\n",
    "            lastChannels = fCount\n",
    "\n",
    "        self.layers = nn.ModuleList(self.layers)\n",
    "                              \n",
    "    def forward(self, input_x, psf):\n",
    "        x = input_x\n",
    "        for l in list(self.layers)[:-1]:\n",
    "            x = F.tanh(l(x))\n",
    "        x = self.layers[-1](x)\n",
    "        \n",
    "        b = (input_x.data.shape[2] - x.data.shape[2]) / 2\n",
    "        input_x = input_x[:, :, b:-b, b:-b]\n",
    "        x = x + input_x \n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "class WeightNet(nn.Module):\n",
    "    def __init__(self, inDim, outDims):\n",
    "        super(WeightNet, self).__init__()\n",
    " \n",
    "        self.expandModule = []\n",
    "        self.expandModule.append(nn.Linear(inDim, 128))\n",
    "        self.expandModule.append(nn.BatchNorm2d(num_features=128, momentum=0.8))\n",
    "        self.expandModule.append(nn.ReLU())\n",
    "        self.expandModule = nn.Sequential(*self.expandModule)\n",
    "        \n",
    "        self.weightModules = nn.ModuleList()\n",
    "        for outDim in outDims:\n",
    "            modul = []\n",
    "            modul.append(nn.Linear(128, outDim))\n",
    "            modul.append(nn.Softmax())\n",
    "            self.weightModules.append(nn.Sequential(*modul))\n",
    "            \n",
    "    def forward(self, input_x):\n",
    "        x = input_x \n",
    "        x = self.expandModule(x)\n",
    "        \n",
    "        outputs = []\n",
    "        for modul in self.weightModules:\n",
    "            outputs.append(modul(x))\n",
    "        \n",
    "        return outputs\n",
    "        \n",
    "        \n",
    "\n",
    "class DeconvNet(nn.Module):\n",
    "    def __init__(self, psfNet, psfDim, filterSizes, filterCounts):\n",
    "        super(DeconvNet, self).__init__()\n",
    "\n",
    "        self.psfNet = psfNet\n",
    "        \n",
    "        self.weightNet = WeightNet(psfDim, filterCounts)\n",
    "        \n",
    "        lastChannels = 3\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.BNlayers = nn.ModuleList()\n",
    "        for fSize, fCount in zip(filterSizes, filterCounts):\n",
    "            self.layers.append(nn.Conv2d(lastChannels, fCount, fSize))\n",
    "            lastChannels = fCount\n",
    "            self.BNlayers.append(nn.BatchNorm2d(num_features=lastChannels, momentum=0.5))\n",
    "\n",
    "        self.lastLayer = nn.Conv2d(lastChannels, 3, 3)\n",
    "            \n",
    "    def forward(self, input_x, psf):\n",
    "        x = input_x\n",
    "        emb = self.psfNet(psf)\n",
    "        weights = self.weightNet(emb)\n",
    "\n",
    "        for i in range(len(self.layers)):\n",
    "            x = self.layers[i](x)\n",
    "            x = x * weights[i].view(x.data.shape[0], x.data.shape[1], 1, 1)\n",
    "            x = self.BNlayers[i](x) \n",
    "            x = F.tanh(x)\n",
    "\n",
    "        x = self.lastLayer(x)\n",
    "        b = (input_x.data.shape[2] - x.data.shape[2]) / 2\n",
    "        input_x = input_x[:, :, b:-b, b:-b]\n",
    "        x = x + input_x \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearNet(nn.Module):\n",
    "\n",
    "    def __init__(self, filterSizes, filterCounts):\n",
    "        super(LinearNet, self).__init__()\n",
    "\n",
    "        lastChannels = 3\n",
    "        self.layers = []\n",
    "        for fSize, fCount in zip(filterSizes, filterCounts):\n",
    "            self.layers.append(nn.Conv2d(lastChannels, fCount, fSize))\n",
    "            lastChannels = fCount\n",
    "\n",
    "        self.layers = nn.ModuleList(self.layers)\n",
    "                              \n",
    "    def forward(self, input_x):\n",
    "        x = input_x\n",
    "        for l in list(self.layers)[:-1]:\n",
    "            x = F.tanh(l(x))\n",
    "        x = self.layers[-1](x)\n",
    "        \n",
    "        b = (input_x.data.shape[2] - x.data.shape[2]) / 2\n",
    "        input_x = input_x[:, :, b:-b, b:-b]\n",
    "        x = x + input_x \n",
    "        \n",
    "        return x\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, ):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.embDim = 32\n",
    "        self.filterSize = 25\n",
    "        self.filterCount = 3\n",
    "        \n",
    "        self.psfEmbed = nn.Embedding(\n",
    "            maxFilterID, self.filterCount*self.filterSize*self.filterSize*3)#self.embDim)\n",
    "        #self.psfFC1 = torch.nn.Linear(self.embDim, 64, bias=False)\n",
    "        #self.psfFC2 = torch.nn.Linear(\n",
    "        #    64, \n",
    "        #    self.filterCount*self.filterSize*self.filterSize*3, \n",
    "        #                              bias=False)\n",
    "        \n",
    "        \n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        #self.conv1 = nn.Conv2d(self.filterCount, 64, 1)\n",
    "        #self.conv2 = nn.Conv2d(64, 3, 7)\n",
    "        \n",
    "    def computeEmb(self, psfIdx):\n",
    "        batchSize = psfIdx.data.shape[0]\n",
    "        f = self.psfEmbed(psfIdx)\n",
    "        #f = f.view(\n",
    "        #    [batchSize, self.filterCount, self.filterSize*self.filterSize*3]).transpose(0,1).clone()\n",
    "        \n",
    "        #f = f.view(f.data.shape[0], f.data.shape[2])\n",
    "        #f = F.relu(self.psfFC1(f))\n",
    "        #f = self.psfFC2(f)\n",
    "        #f = F.softmax(f)\n",
    "        #f = f.view(batchSize, self.filterCount*3, self.filterSize, self.filterSize)\n",
    "        \n",
    "        #f = f.view(batchSize, self.filterCount, 3 , self.filterSize, self.filterSize)\n",
    "        \n",
    "        return f\n",
    "    \n",
    "    def forward(self, input_x, psf):\n",
    "        batchSize = psfIdx.data.shape[0]\n",
    "        \n",
    "        f = self.computeEmb(psfIdx)\n",
    "        x = input_x\n",
    "        res = []\n",
    "        for i in range(batchSize):\n",
    "            img = x[i:i+1]\n",
    "            w = f[i].view(self.filterCount, 3, self.filterSize, self.filterSize)\n",
    "            res.append(F.conv2d(img, w))\n",
    "        res = torch.cat(res, dim=0)\n",
    "\n",
    "        #x = x.view(1, x.data.shape[0]*x.data.shape[1],\n",
    "        #          x.data.shape[2], x.data.shape[3])\n",
    "        #x = F.tanh(res)\n",
    "        #x = x.view(batchSize, self.filterCount, x.data.shape[2], x.data.shape[3])\n",
    "        \n",
    "        #x = F.relu(self.conv1(x))\n",
    "        #x = self.conv2(x)\n",
    "        \n",
    "        #b = (input_x.data.shape[2] - x.data.shape[2]) / 2\n",
    "        #input_x = input_x[:, :, b:-b, b:-b]\n",
    "        #x = x + input_x \n",
    "        \n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PsfNet(nn.Module):\n",
    "\n",
    "    def __init__(self, input_img, embeddingDim):\n",
    "        super(PsfNet, self).__init__()\n",
    "\n",
    "        self.filterSizes = [5, 3, 3]\n",
    "        self.filterCounts = [24, 48, 64]\n",
    "        self.strides = [1, 2, 1]\n",
    "        self.fcSizes = [128, embeddingDim]\n",
    "        \n",
    "        lastChannels = input_img.data.shape[1]\n",
    "        self.convLayers = []\n",
    "        for fSize, fCount, stride in zip(self.filterSizes, self.filterCounts, self.strides):\n",
    "            self.convLayers.append(nn.Conv2d(in_channels=lastChannels, \n",
    "                                             out_channels=fCount, \n",
    "                                             kernel_size=fSize, \n",
    "                                             stride=stride))\n",
    "            lastChannels = fCount\n",
    "            self.convLayers.append(nn.BatchNorm2d(num_features=lastChannels, momentum=0.5))\n",
    "            self.convLayers.append(nn.ReLU())\n",
    "        \n",
    "        self.convLayers = nn.Sequential(*self.convLayers).cuda()\n",
    "        out = self.convLayers(input_img)\n",
    "        print('Conv output shape:', out.data.shape)\n",
    "        \n",
    "        lastChannels = out.data.shape[1]*out.data.shape[2]*out.data.shape[3]\n",
    "        self.fcLayers = []\n",
    "        for size in self.fcSizes[:-1]:\n",
    "            self.fcLayers.append(nn.Linear(lastChannels, size))\n",
    "            lastChannels = size\n",
    "            #self.fcLayers.append(nn.BatchNorm2d(num_features=lastChannels, momentum=0.3))\n",
    "            self.fcLayers.append(nn.ReLU())\n",
    "            \n",
    "        self.fcLayers.append(nn.Linear(lastChannels, self.fcSizes[-1]))\n",
    "        lastChannels = self.fcSizes[-1]\n",
    "           \n",
    "        self.fcLayers = nn.Sequential(*self.fcLayers).cuda()\n",
    "        \n",
    "        self.outBNorm = nn.BatchNorm1d(lastChannels, momentum=0.5)\n",
    "        \n",
    "    def forward(self, input_x):\n",
    "        x = input_x\n",
    "        x = self.convLayers(x)\n",
    "        x = x.view(x.data.shape[0], -1)\n",
    "        x = self.fcLayers(x)\n",
    "        x = F.normalize(x, p=2, dim=1, eps=1e-12)\n",
    "        x = self.outBNorm(x)\n",
    "        return x\n",
    "\n",
    "class LinearFilterNet(nn.Module):\n",
    "\n",
    "    def __init__(self, filterSizes, filterCounts):\n",
    "        super(LinearNet, self).__init__()\n",
    "\n",
    "        lastChannels = 3\n",
    "        self.layers = []\n",
    "        for fSize, fCount in zip(filterSizes, filterCounts):\n",
    "            self.layers.append(nn.Conv2d(lastChannels, fCount, fSize))\n",
    "            lastChannels = fCount\n",
    "\n",
    "        self.layers = nn.ModuleList(self.layers)\n",
    "                              \n",
    "    def forward(self, input_x, psf):\n",
    "        x = input_x\n",
    "        for l in list(self.layers)[:-1]:\n",
    "            x = F.tanh(l(x))\n",
    "        x = self.layers[-1](x)\n",
    "        \n",
    "        b = (input_x.data.shape[2] - x.data.shape[2]) / 2\n",
    "        input_x = input_x[:, :, b:-b, b:-b]\n",
    "        x = x + input_x \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class WeightNet(nn.Module):\n",
    "    def __init__(self, inDim, outDims):\n",
    "        super(WeightNet, self).__init__()\n",
    " \n",
    "        self.expandModule = []\n",
    "        self.expandModule.append(nn.Linear(inDim, 128))\n",
    "        self.expandModule.append(nn.BatchNorm2d(num_features=128, momentum=0.5))\n",
    "        self.expandModule.append(nn.ReLU())\n",
    "        self.expandModule = nn.Sequential(*self.expandModule)\n",
    "        \n",
    "        self.weightModules = nn.ModuleList()\n",
    "        for outDim in outDims:\n",
    "            modul = []\n",
    "            modul.append(nn.Linear(128, outDim))\n",
    "            modul.append(nn.Softmax())\n",
    "            self.weightModules.append(nn.Sequential(*modul))\n",
    "            \n",
    "    def forward(self, input_x):\n",
    "        x = input_x \n",
    "        x = self.expandModule(x)\n",
    "        \n",
    "        outputs = []\n",
    "        for modul in self.weightModules:\n",
    "            outputs.append(modul(x))\n",
    "        \n",
    "        return outputs\n",
    "        \n",
    "        \n",
    "\n",
    "class DeconvNet(nn.Module):\n",
    "    def __init__(self, psfNet, psfDim, filterSizes, filterCounts):\n",
    "        super(DeconvNet, self).__init__()\n",
    "\n",
    "        self.psfNet = psfNet\n",
    "        \n",
    "        self.weightNet = WeightNet(psfDim, filterCounts)\n",
    "        \n",
    "        lastChannels = 3\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.BNlayers = nn.ModuleList()\n",
    "        for fSize, fCount in zip(filterSizes, filterCounts):\n",
    "            self.layers.append(nn.Conv2d(lastChannels, fCount, fSize))\n",
    "            lastChannels = fCount\n",
    "            self.BNlayers.append(nn.BatchNorm2d(num_features=lastChannels, momentum=0.5))\n",
    "\n",
    "        self.lastLayer = nn.Conv2d(lastChannels, 3, 3)\n",
    "            \n",
    "    def forward(self, input_x, psf):\n",
    "        x = input_x\n",
    "        emb = self.psfNet(psf)\n",
    "        weights = self.weightNet(emb)\n",
    "\n",
    "        for i in range(len(self.layers)):\n",
    "            x = self.layers[i](x)\n",
    "            x = x * weights[i].view(x.data.shape[0], x.data.shape[1], 1, 1)\n",
    "            x = self.BNlayers[i](x) \n",
    "            x = F.tanh(x)\n",
    "\n",
    "        x = self.lastLayer(x)\n",
    "        b = (input_x.data.shape[2] - x.data.shape[2]) / 2\n",
    "        input_x = input_x[:, :, b:-b, b:-b]\n",
    "        x = x + input_x \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getData(reader, batchSize, cropSize, maxNoise = 0):\n",
    "    data, idx, psf = reader.getBatch(batchSize, cropSize)\n",
    "    Tidx = Variable(torch.LongTensor(idx).view(batchSize, 1).cuda())\n",
    "    Tdata = Variable(torch.Tensor(data.astype(dtype=np.float32)).cuda())\n",
    "    Tpsf = Variable(torch.Tensor(psf.astype(dtype=np.float32)).cuda())\n",
    "    blurred = F.conv2d(\n",
    "        Tdata.view(1, 3*batchSize, Tdata.data.shape[2], Tdata.data.shape[3]),\n",
    "        Tpsf.view(3*batchSize, 1, Tpsf.data.shape[2], Tpsf.data.shape[3]),\n",
    "        groups=3*batchSize)\n",
    "\n",
    "    blurred = blurred.view(batchSize, 3, blurred.data.shape[2], blurred.data.shape[3])\n",
    "    \n",
    "    if maxNoise > 0:\n",
    "        noiseEnergy = torch.cuda.FloatTensor(blurred.data.shape[0]).uniform_(0, maxNoise).view(-1, 1, 1, 1)\n",
    "        blurred += Variable(torch.cuda.FloatTensor(blurred.data.shape).normal_() * noiseEnergy)\n",
    "    \n",
    "    return blurred, Tdata, Tpsf, Tidx, \n",
    "\n",
    "psfEmbeddingDim = 64\n",
    "blurred, sharp, psf, fid = getData(dataSource, 2, 150)\n",
    "psfNet = PsfNet(psf, psfEmbeddingDim).cuda()\n",
    "out = psfNet(psf)\n",
    "print(out.data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "net = DeconvNet(psfNet, psfEmbeddingDim, [35,1,1,3,3,3,3,3], [64,128,128,64,64,64,64,64])\n",
    "print(net)\n",
    "net.cuda()\n",
    "net(blurred, psf)\n",
    "\n",
    "lossHistory = []\n",
    "lossPositions = []\n",
    "iteration = 0\n",
    "\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.0004)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxNoise = 4.0 / 256.0\n",
    "acc = 0\n",
    "dataAcc = 0\n",
    "iterationAcc = 0\n",
    "targetSize = 28\n",
    "testSize = 150\n",
    "blurred, sharp, psf, fid = getData(dataSource, 1, testSize, maxNoise)\n",
    "out = net(blurred, psf)\n",
    "border = testSize - out.data.shape[2]\n",
    "cropSize = targetSize + border\n",
    "print('Crop size:', cropSize, 'border:', border)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = torch.load('model_105999.mod')\n",
    "net.load_state_dict(d)\n",
    "iteration = 106000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "maxNoise = 5.0 / 256.0\n",
    "blurred, sharp, psf, fid = getData(dataSource, 1, testSize, maxNoise)\n",
    "out = net(blurred, psf)\n",
    "batchSize = 128\n",
    "viewStep = 20\n",
    "\n",
    "for i in range(1000000):\n",
    "    iteration += 1\n",
    "    optimizer.zero_grad()\n",
    "    blurred, sharp, psf, fid = getData(dataSource, batchSize, cropSize, maxNoise)\n",
    "    \n",
    "    out = net(blurred, psf)\n",
    "    b = ((sharp.data.shape[2] - out.data.shape[2])/2, \n",
    "              (sharp.data.shape[3] - out.data.shape[3])/2)\n",
    "    loss = criterion(out, sharp[:,:,b[0]:-b[0],b[1]:-b[1]])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    iterationAcc += 1\n",
    "    acc += loss.data[0]\n",
    "\n",
    "    b2 = ((sharp.data.shape[2] - blurred.data.shape[2])/2, \n",
    "              (sharp.data.shape[3] - blurred.data.shape[3])/2)\n",
    "    dataLoss = criterion(blurred, sharp[:, :, b2[0]:-b2[0], b2[1]:-b2[1]])\n",
    "    dataAcc += dataLoss.data[0]\n",
    "\n",
    "    if iteration % viewStep == viewStep-1 and iterationAcc > viewStep / 3:\n",
    "        #net.eval()\n",
    "        acc /= iterationAcc\n",
    "        dataAcc /= iterationAcc\n",
    "        iterationAcc = 0\n",
    "        print(iteration, acc, dataAcc)\n",
    "        lossHistory.append(acc) \n",
    "        lossPositions.append(iteration)\n",
    "        acc = 0\n",
    "        dataAcc = 0 \n",
    "        vizSize = 128\n",
    "        vizBatchSize = 32\n",
    "        \n",
    "        blurred, sharp, psf, fid = getData(dataSource, vizBatchSize, vizSize+border, maxNoise)\n",
    "        out = net(blurred, psf)\n",
    "        res = out.data.cpu().numpy()\n",
    "        print(res.min(), res.max())\n",
    "        \n",
    "        fig = plt.figure(figsize=(14, 10), dpi=80, facecolor='w', edgecolor='k')\n",
    "        plt.subplot(1, 2, 1)\n",
    "        res = np.maximum(np.minimum(res, 1.0), 0.0)\n",
    "        recColl = collage(res)\n",
    "        plt.imshow(recColl[:512,:512,::-1])\n",
    "        \n",
    "        b = (blurred.data.shape[2] - out.data.shape[2]) / 2\n",
    "        blurred = blurred[:, :, b:-b, b:-b]\n",
    "        blurred = blurred.data.cpu().numpy()\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        blurColl = collage(blurred)\n",
    "        plt.imshow(blurColl[:512,:512,::-1])\n",
    "        \n",
    "        '''plt.subplot(1, 2, 2)\n",
    "        filterCount = 16\n",
    "        psfIdx = Variable(torch.LongTensor(range(filterCount)).view(filterCount, 1).cuda())\n",
    "        f = net.computeEmb(psfIdx).view(filterCount*net.filterCount, 3, net.filterSize, net.filterSize)\n",
    "        data = f.data.cpu()\n",
    "        data -= data.min()\n",
    "        data /= data.max()\n",
    "        data = data.numpy()\n",
    "        print(data.shape)\n",
    "        img = collage(data)\n",
    "        plt.imshow(img)\n",
    "        print(img.shape)\n",
    "        '''\n",
    "        plt.draw()\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "\n",
    "        l0 = net.layers[0]\n",
    "        l0 = l0.weight.data.cpu().numpy()\n",
    "        l0 -= l0.min()\n",
    "        l0 /= l0.max()\n",
    "\n",
    "        filterColl = collage(l0)\n",
    "        plt.imshow(filterColl[:,:,::-1])\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(lossPositions, lossHistory)\n",
    "        plt.show()\n",
    "        net.train()\n",
    "        np.savez('loss_2.npz', lossPositions, lossHistory)\n",
    "        cv2.imwrite('{:06d}_blur.png'.format(iteration), blurColl*256)\n",
    "        cv2.imwrite('{:06d}_rec.png'.format(iteration), recColl*256)\n",
    "        cv2.imwrite('filter_{:06d}.png'.format(iteration), filterColl*256)\n",
    "        torch.save(net.state_dict(), 'model_{:06d}.mod'.format(iteration))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lossPositions[1:], lossHistory[1:])\n",
    "print(iteration, iterationAcc)\n",
    "l0 = net.layers[0]\n",
    "l0 = l0.weight.data.cpu().numpy()\n",
    "l0 -= l0.min()\n",
    "l0 /= l0.max()\n",
    "\n",
    "img = collage(l0)\n",
    "#plt.imshow(img[:,:,::-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = net.psfEmbed.weight.data.cpu()\n",
    "data -= data.min()\n",
    "data /= data.max()\n",
    "data = data.numpy()\n",
    "data = data.reshape(data.shape[0]*net.filterCount, 3, net.filterSize, net.filterSize)\n",
    "print(data.shape)\n",
    "img = collage(data)\n",
    "plt.imshow(img)\n",
    "plt.draw()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = out.data.cpu().numpy()\n",
    "img = collage(res)\n",
    "print(img.shape, res.shape, data.shape)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img/255.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psfIdx = Variable(Tidx.cuda())\n",
    "f = net.psfEmbed(psfIdx)\n",
    "f = f.view(f.data.shape[0], f.data.shape[2])\n",
    "f = F.relu(net.psfFC1(f))\n",
    "f = net.psfFC2(f)\n",
    "f = F.softmax(f)\n",
    "f = f.view(128, 3, net.filterSize, net.filterSize)\n",
    "\n",
    "res = f.data.cpu().numpy()\n",
    "plt.subplot(1, 2, 1)\n",
    "img = collage(res[:16,:,:,:], True)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
