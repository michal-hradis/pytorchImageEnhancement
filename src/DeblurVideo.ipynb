{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "%matplotlib inline  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SqueezeExitationBlock(nn.Module):\n",
    "    def __init__(self, inputChannels, filterSize=3, filterCount=32):\n",
    "        super(SqueezeExitationBlock, self).__init__()\n",
    "        \n",
    "        if filterSize > 3:\n",
    "            self.layer1 = nn.Conv2d(in_channels=inputChannels, \n",
    "                                     padding=0,\n",
    "                                     out_channels=filterCount, \n",
    "                                     kernel_size=filterSize)\n",
    "        else:\n",
    "            self.layer1 = nn.Conv2d(in_channels=inputChannels, \n",
    "                                     padding=(filterSize-1)/2,\n",
    "                                     out_channels=filterCount, \n",
    "                                     kernel_size=filterSize)\n",
    "\n",
    "        self.sqeeze = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1,1)),\n",
    "            nn.Conv2d(in_channels=filterCount, \n",
    "                     out_channels=filterCount, \n",
    "                     kernel_size=1),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "        self.output = nn.Sequential(\n",
    "            nn.BatchNorm2d(num_features=filterCount, momentum=0.75),\n",
    "            nn.ReLU()\n",
    "            )\n",
    "        \n",
    "    def forward(self, input_x):\n",
    "        act = self.layer1(input_x)\n",
    "        weights = self.sqeeze(act)\n",
    "        out = self.output(act * weights)\n",
    "        return out\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, inputChannels, filterSize=3, filterCount=32):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        \n",
    "        if filterSize > 3:\n",
    "            self.layer1 = nn.Conv2d(in_channels=inputChannels, \n",
    "                                     padding=0,\n",
    "                                     out_channels=filterCount, \n",
    "                                     kernel_size=filterSize)\n",
    "        else:\n",
    "            self.layer1 = nn.Conv2d(in_channels=inputChannels, \n",
    "                                     padding=(filterSize-1)/2,\n",
    "                                     out_channels=filterCount, \n",
    "                                     kernel_size=filterSize)\n",
    "\n",
    "\n",
    "        self.output = nn.Sequential(\n",
    "            nn.BatchNorm2d(num_features=filterCount, momentum=0.75),\n",
    "            nn.ReLU()\n",
    "            )\n",
    "        \n",
    "    def forward(self, input_x):\n",
    "        act = self.layer1(input_x)\n",
    "        out = self.output(act)\n",
    "        return out\n",
    "    \n",
    "class LinearBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, inputChannels, filterSizes=[3, 3], filterCounts=[32, 32]):\n",
    "        super(LinearBlock, self).__init__()\n",
    "        \n",
    "        lastChannels = inputChannels\n",
    "        convLayers = []\n",
    "        for fSize, fCount in zip(filterSizes, filterCounts):\n",
    "            #if inputChannels > 6:\n",
    "            #    convLayers.append(torch.nn.Dropout2d(p=0.2))\n",
    "            convLayers.append(\n",
    "                ConvBlock(inputChannels=lastChannels, \n",
    "                                      filterCount=fCount, \n",
    "                                      filterSize=fSize))\n",
    "            lastChannels = fCount\n",
    "\n",
    "        self.convLayers = nn.Sequential(*convLayers)\n",
    "        \n",
    "    def forward(self, input_x):\n",
    "        return self.convLayers(input_x)\n",
    "    \n",
    "    \n",
    "    \n",
    "class AggregationNet(nn.Module):\n",
    "    def __init__(self, inputChannels, outChannels):\n",
    "        super(AggregationNet, self).__init__()\n",
    "        self.compressBlockInfo = [(2, 16), (2, 24), (2, 32)]        \n",
    "        self.compressBlocks = torch.nn.ModuleList()\n",
    "   \n",
    "        filterSizes = [13, 1, 3]    \n",
    "        filterCounts = [32, 32, 16]\n",
    "        self.compressBlocks.append(LinearBlock(inputChannels, filterSizes, filterCounts))\n",
    "        lastChannels = filterCounts[-1]\n",
    "\n",
    "        for layerCount, filterCount in self.compressBlockInfo[1:]:\n",
    "            filterSizes = [3 for i in range(layerCount)]    \n",
    "            filterCounts = [filterCount for i in range(layerCount)]\n",
    "            self.compressBlocks.append(LinearBlock(lastChannels, filterSizes, filterCounts))\n",
    "            lastChannels = filterCount\n",
    "        \n",
    "        self.outLayers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=lastChannels, out_channels=256, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1,1)),\n",
    "            nn.Conv2d(in_channels=256, out_channels=outChannels, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            );\n",
    "        \n",
    "    def forward(self, input_x):\n",
    "        x = input_x\n",
    "        for i, module in enumerate(self.compressBlocks):\n",
    "            x = module(x)\n",
    "            x = F.max_pool2d(x, 2, stride=2)\n",
    "        x = self.outLayers(x)\n",
    "            \n",
    "        return x\n",
    "    \n",
    "class ColorNet(nn.Module):\n",
    "    def __init__(self, inputChannels, modulationChannels):\n",
    "        super(ColorNet, self).__init__()\n",
    "        \n",
    "        self.filterCount = 16\n",
    "        self.filterCounts = [self.filterCount, self.filterCount]\n",
    "        self.layerMultipliers = torch.nn.ModuleList()\n",
    "        self.layerBN = torch.nn.ModuleList()\n",
    "        \n",
    "        for fCount in self.filterCounts:\n",
    "            self.layerMultipliers.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv2d(in_channels=modulationChannels, out_channels=fCount, kernel_size=1),\n",
    "                    nn.Softmax2d(),\n",
    "                )\n",
    "            )\n",
    "            self.layerBN.append(\n",
    "                 nn.BatchNorm2d(num_features=fCount, momentum=0.75))     \n",
    "            \n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        self.layers.append(\n",
    "            nn.Conv2d(in_channels=inputChannels*3, out_channels=self.filterCount, kernel_size=1, padding=0))\n",
    "        self.layers.append(\n",
    "            nn.Conv2d(in_channels=self.filterCount, out_channels=self.filterCount, kernel_size=1, padding=0))\n",
    "        \n",
    "        self.lastLayer = nn.Conv2d(in_channels=self.filterCount, out_channels=inputChannels, kernel_size=1, padding=0)\n",
    "    \n",
    "    def forward(self, input_x, modulation):\n",
    "        x = torch.cat((input_x, torch.pow(input_x, 2), torch.pow(input_x, 3)), dim=1)\n",
    "        for layer, multiplier, bNorm in zip(self.layers, self.layerMultipliers, self.layerBN):\n",
    "            x = F.relu((layer(x)) * multiplier(modulation), inplace=True)\n",
    "            x = bNorm(x)\n",
    "            \n",
    "        x = F.tanh(self.lastLayer(x))\n",
    "        return x       \n",
    "    \n",
    "class FilterNet(nn.Module):\n",
    "    def __init__(self, inputChannels, filterSize):\n",
    "        super(FilterNet, self).__init__()\n",
    "\n",
    "        self.filterSize = filterSize\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=inputChannels, out_channels=512, kernel_size=1),\n",
    "            nn.BatchNorm2d(num_features=512, momentum=0.75),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=1),\n",
    "            nn.BatchNorm2d(num_features=512, momentum=0.75),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=1),\n",
    "            nn.BatchNorm2d(num_features=512, momentum=0.75),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=512, out_channels=filterSize*filterSize, kernel_size=1))\n",
    "    \n",
    "    def forward(self, input_x):\n",
    "        x = self.layers(input_x)\n",
    "        x = F.softmax(x)\n",
    "        return x.view(x.data.shape[0], 1, self.filterSize, self.filterSize)       \n",
    "\n",
    "class HourGlassNet(nn.Module):\n",
    "\n",
    "    def __init__(self, inputChannels, aggChannels):\n",
    "        super(HourGlassNet, self).__init__()\n",
    "        \n",
    "        self.compressBlockInfo = [(2, 24), (2, 32), (3, 64)]\n",
    "        self.decompressBlockInfo = [(2, 32), (2, 24)]\n",
    "        self.compressBlocks = torch.nn.ModuleList()\n",
    "        self.decompressBlocks = torch.nn.ModuleList()\n",
    "\n",
    "\n",
    "        self.blockMultipliers = torch.nn.ModuleList()\n",
    "        self.blockBN = torch.nn.ModuleList()\n",
    "        for fCount in [j[1] for j in self.compressBlockInfo + self.decompressBlockInfo]:\n",
    "            self.blockMultipliers.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv2d(in_channels=aggChannels, out_channels=fCount, kernel_size=1),\n",
    "                    nn.Softmax2d(),\n",
    "                )\n",
    "            )\n",
    "            self.blockBN.append(\n",
    "                 nn.BatchNorm2d(num_features=fCount, momentum=0.75))\n",
    "\n",
    "        lastChannels = inputChannels\n",
    "\n",
    "        filterSizes = [13, 1, 3]    \n",
    "        filterCounts = [64, 32, 24]\n",
    "        self.compressBlocks.append(LinearBlock(lastChannels, filterSizes, filterCounts))\n",
    "        lastChannels = filterCounts[-1]\n",
    "\n",
    "        for layerCount, filterCount in self.compressBlockInfo[1:]:\n",
    "            filterSizes = [3 for i in range(layerCount)]    \n",
    "            filterCounts = [filterCount for i in range(layerCount)]\n",
    "            self.compressBlocks.append(LinearBlock(lastChannels, filterSizes, filterCounts))\n",
    "            lastChannels = filterCount\n",
    "\n",
    "        compressFilterCounts = [fc for lc, fc in self.compressBlockInfo[:-1]]\n",
    "\n",
    "        for compressFC, (layerCount, filterCount) in zip(compressFilterCounts[::-1], self.decompressBlockInfo):\n",
    "            filterSizes = [3 for i in range(layerCount)]    \n",
    "            filterCounts = [filterCount for i in range(layerCount)]\n",
    "            self.decompressBlocks.append(LinearBlock(lastChannels + compressFC, filterSizes, filterCounts))\n",
    "            lastChannels = filterCount\n",
    "        \n",
    "        \n",
    "        fSize = 3\n",
    "        self.outputLayer = nn.Conv2d(in_channels=lastChannels, \n",
    "                                          padding=(fSize-1)/2,\n",
    "                                          out_channels=inputChannels, \n",
    "                                          kernel_size=fSize)\n",
    "        \n",
    "    def forward(self, input_x, agg):\n",
    "        blockMultipliers = list(self.blockMultipliers)\n",
    "        blockBN = list(self.blockBN)\n",
    "        \n",
    "        x = input_x\n",
    "        compressStages = []\n",
    "        for i, module in enumerate(self.compressBlocks):\n",
    "            x = module(x)\n",
    "            x = blockBN[0](x * blockMultipliers[0](agg))\n",
    "            blockMultipliers = blockMultipliers[1:]\n",
    "            blockBN = blockBN[1:]\n",
    "            if i < len(self.compressBlocks) -1:\n",
    "                compressStages.append(x)\n",
    "                x = F.max_pool2d(x, 2, stride=2)\n",
    "        \n",
    "        for module, bypass in zip(self.decompressBlocks, compressStages[::-1]):\n",
    "            x = F.upsample_nearest(x, scale_factor=2)\n",
    "            x = torch.cat((x, bypass), dim=1)\n",
    "            x = module(x)\n",
    "            x = blockBN[0](x * blockMultipliers[0](agg))\n",
    "            blockMultipliers = blockMultipliers[1:]\n",
    "            blockBN = blockBN[1:]\n",
    "            \n",
    "        x = self.outputLayer(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class FullNet(nn.Module):\n",
    "\n",
    "    def __init__(self, inputChannels, aggregationNet, colorNet, filterNet, reconstructNet):\n",
    "        super(FullNet, self).__init__()\n",
    "        \n",
    "        self.aggregation = aggregationNet\n",
    "        self.colorNet = colorNet\n",
    "        self.reconstructNet = reconstructNet\n",
    "        self.filterNet = filterNet\n",
    "        \n",
    "    def forward(self, input_x):\n",
    "        agg = self.aggregation(input_x)\n",
    "        color_correction = self.colorNet(input_x, agg)\n",
    "        psf = self.filterNet(agg)\n",
    "        \n",
    "        x = self.reconstructNet(color_correction, agg)\n",
    "\n",
    "        return x, color_correction, psf       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgEmbedding = 256\n",
    "aggNet = AggregationNet(3, imgEmbedding)\n",
    "colorNet = ColorNet(3, imgEmbedding)\n",
    "recNet = HourGlassNet(3, imgEmbedding)\n",
    "filterNet = FilterNet(imgEmbedding, 21)\n",
    "net = FullNet(3, aggNet, colorNet, filterNet, recNet)\n",
    "print(net)\n",
    "net.cuda()\n",
    "\n",
    "lossHistory = []\n",
    "lossPositions = []\n",
    "iteration = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load('model_279999.mod'))\n",
    "net = net.cuda().train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "print(cap.isOpened())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "size = 256\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    b0 = (frame.shape[0] - size) / 2\n",
    "    b1 = (frame.shape[1] - size) / 2\n",
    "    \n",
    "    crop = frame[b0:b0+size, b1:b1+size]\n",
    "    data = crop.transpose(2, 0, 1).reshape(1,3,size,size).astype(np.float32)\n",
    "    t1 = time()\n",
    "    data = Variable(torch.from_numpy(data).cuda() / 255)\n",
    "    out, color_correction, t = net(data)\n",
    "    \n",
    "    out = out.data.cpu().numpy()[0].transpose(1, 2, 0)\n",
    "    t2 = time()\n",
    "    # print( t2-t1)\n",
    "    color_correction = color_correction.data.cpu().numpy()[0].transpose(1, 2, 0)   \n",
    "\n",
    "    cv2.imshow('in', crop)\n",
    "    cv2.imshow('out', out)\n",
    "    cv2.imshow('color',color_correction)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == 27:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(frame.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.Tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
