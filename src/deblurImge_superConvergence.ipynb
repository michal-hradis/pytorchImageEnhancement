{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "%matplotlib inline  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from data import DataSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filterCount=500\n",
    "#del dataSource\n",
    "dataSource = DataSource(\n",
    "    '/home/ihradis/projects/2016-07-07_JPEG/data/skyscraper.tst', \n",
    "    '/home/ihradis/projects/2016-07-07_JPEG/data/',\n",
    "    minSize=250, length=[15,15], filterCount=filterCount) \n",
    "print(len(dataSource.images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeblurClassic(nn.Module):\n",
    "\n",
    "    def __init__(self, image, psf):\n",
    "        super(DeblurClassic, self).__init__()\n",
    "        self.image = nn.Parameter(image.clone(), requires_grad=True)\n",
    "        self.psf = Variable(psf.view(3, 1, psf.shape[2], psf.shape[3]).clone())\n",
    "        self.c0 = Variable(torch.FloatTensor([0])).view(1,1,1,1)\n",
    "        self.c1 = Variable(torch.FloatTensor([1])).view(1,1,1,1)\n",
    "                              \n",
    "    def forward(self):\n",
    "        x = F.conv2d(self.image, self.psf, groups=3)\n",
    "        dx = torch.abs(self.image[:,:,1:,:]-self.image[:,:,:-1,:])**1.2\n",
    "        dy = torch.abs(self.image[:,:,:,1:]-self.image[:,:,:,:-1])**1.2\n",
    "        dd = torch.sum((dx + dy)) / (dx.data.shape[1] * dx.data.shape[2] * dx.data.shape[3])\n",
    "        return x, dd\n",
    "    \n",
    "    def constrain(self):\n",
    "        self.image.data[...] = torch.max(self.image, self.c0).data\n",
    "        self.image.data[...] = torch.min(self.image, self.c1).data\n",
    "\n",
    "        \n",
    "        \n",
    "class DeblurGAN(nn.Module):\n",
    "    def __init__(self, images, psf):\n",
    "        super(DeblurGAN, self).__init__()\n",
    "        self.images = nn.Parameter(images.clone(), requires_grad=True)\n",
    "        self.psf = Variable(psf.view(\n",
    "            psf.shape[0]*psf.shape[1], 1, \n",
    "            psf.shape[2], psf.shape[3]).clone()).cuda()\n",
    "        self.c0 = Variable(torch.FloatTensor([0])).view(1,1,1,1).cuda()\n",
    "        self.c1 = Variable(torch.FloatTensor([1])).view(1,1,1,1).cuda()\n",
    "        self.normPower = 1.2\n",
    "        self.register_buffer('psf', self.psf)\n",
    "        self.register_buffer('c0', self.c0)\n",
    "        self.register_buffer('c1', self.c1)\n",
    "        print(self.images.data[0,0,0,0], self.psf[0,0,0,0])\n",
    "\n",
    "    def forward(self):\n",
    "        #if self.use_gpu:\n",
    "        #    self.images = self.images.cuda()\n",
    "        #    self.psf = self.psf.cuda()\n",
    "        \n",
    "        x = self.images.view(1, -1, self.images.data.shape[2], self.images.data.shape[3])\n",
    "        x = F.conv2d( x, self.psf, groups=self.psf.data.shape[0])\n",
    "        x = x.view(-1, 3, x.data.shape[2], x.data.shape[3])\n",
    "        dx = torch.abs(self.images[:,:,1:,:]-self.images[:,:,:-1,:])**self.normPower\n",
    "        dy = torch.abs(self.images[:,:,:,1:]-self.images[:,:,:,:-1])**self.normPower\n",
    "        dd = torch.sum((dx + dy)) / (dx.data.shape[0] * dx.data.shape[1] * dx.data.shape[2] * dx.data.shape[3])\n",
    "        return x, dd\n",
    "    \n",
    "    def constrain(self):\n",
    "        self.images.data[...] = torch.max(self.images, self.c0).data\n",
    "        self.images.data[...] = torch.min(self.images, self.c1).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeblurDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeblurDiscriminator, self).__init__()\n",
    "        baseCount = 32\n",
    "        self.convLayers = nn.Sequential(\n",
    "            nn.Conv2d(3, baseCount, 7), nn.PReLU(),\n",
    "            nn.Conv2d(baseCount, baseCount, 3), nn.PReLU(),\n",
    "            nn.Conv2d(baseCount, 1, 3),\n",
    "            nn.AdaptiveAvgPool2d((1,1))\n",
    "        )\n",
    "                              \n",
    "    def forward(self, x):\n",
    "        x = self.convLayers(x).view(-1, 2)\n",
    "        x = F.sigmoid(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(reader, batchSize, cropSize, maxNoise = 0.08):\n",
    "    data, idx, psf = reader.getBatch(batchSize, cropSize)\n",
    "    data = (data-0.1) / 0.8\n",
    "    \n",
    "    data = Variable(torch.Tensor(data.astype(dtype=np.float32)).clone()).cuda()\n",
    "    psf = Variable(torch.Tensor(psf.astype(dtype=np.float32)).clone()).cuda()\n",
    "    blurred = F.conv2d(\n",
    "        data.view(1, 3*batchSize, data.data.shape[2], data.data.shape[3]),\n",
    "        psf.view(3*batchSize, 1, psf.data.shape[2], psf.data.shape[3]),\n",
    "        groups=3*batchSize)\n",
    "    \n",
    "    blurred = blurred.view(batchSize, 3, blurred.data.shape[2], blurred.data.shape[3])\n",
    "    \n",
    "    if maxNoise > 0:\n",
    "        #noiseEnergy = torch.FloatTensor(blurred.data.shape[0]).uniform_(0, maxNoise).view(-1, 1, 1, 1)\n",
    "        blurred += Variable(torch.cuda.FloatTensor(blurred.data.shape).normal_() * maxNoise)\n",
    "    \n",
    "    return blurred, data, psf, idx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageRepository(Object)\n",
    "    def __init__(self, dataReader, size=128, activeMemory=500, iterations=100):\n",
    "        self.reader = dataReader\n",
    "        criterion = torch.nn.MSELoss()\n",
    "\n",
    "    def sharpen(self, )\n",
    "        iterations\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=0.2)\n",
    "        \n",
    "        net = DeblurClassic(blurred.data, psf.data)\n",
    "        net.cuda()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bunchSize = 16\n",
    "resolution = 128\n",
    "bunchCount = 10\n",
    "noise = 0.004\n",
    "\n",
    "deblurNets = []\n",
    "originalImages = []\n",
    "blurredImages = []\n",
    "imageOptimizers = []\n",
    "for i in range(bunchCount):\n",
    "    blurred, sharp, psf, fid = getData(dataSource, bunchSize, resolution, noise)\n",
    "    deblurNets.append(DeblurGAN(blurred.data.cpu(), psf.data.cpu()))\n",
    "    originalImages.append(sharp.data)\n",
    "    blurredImages.append(blurred.data)\n",
    "    imageOptimizers.append(torch.optim.Adam(deblurNets[-1].parameters(), lr=0.001))\n",
    "\n",
    "for i in range(bunchCount):\n",
    "    deblurNets[i].cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = DeblurDiscriminator()\n",
    "discriminator.cuda()\n",
    "dOptimizator = torch.optim.Adam(discriminator.parameters(), lr=0.0001)\n",
    "dCriterion = nn.BCELoss()\n",
    "imgCriterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def cropTensor(what, to):\n",
    "    b = ((what.data.shape[2] - to.data.shape[2])/2, \n",
    "      (what.data.shape[3] - to.data.shape[3])/2)\n",
    "    return what[:, :, b[0]:-b[0], b[1]:-b[1]]\n",
    "from helper import collage\n",
    "\n",
    "accCount = 0\n",
    "accDLoss = 0\n",
    "accRecLoss = 0\n",
    "accGenLoss = 0\n",
    "for i in range(1000000):\n",
    "    # train discriminator\n",
    "    bunch = np.random.randint(bunchCount)\n",
    "    out, dd = deblurNets[bunch]()\n",
    "    \n",
    "    #burred, sharp, psf, fid = getData(dataSource, bunchSize, resolution, noise)\n",
    "    sharp = Variable(originalImages[bunch])\n",
    "    sharp = cropTensor(sharp, out)\n",
    "    batch = Variable(torch.cat([sharp.data.cuda(), out.data]))\n",
    "    labels = Variable(torch.cat([torch.ones(sharp.data.shape[0])*0.9, \n",
    "                     torch.zeros(sharp.data.shape[0])]))\n",
    "\n",
    "    dOptimizator.zero_grad()\n",
    "    dOut = discriminator(batch)\n",
    "    dLoss = dCriterion(dOut, labels.cuda())\n",
    "    dLoss.backward()\n",
    "    dOptimizator.step()\n",
    "    \n",
    "    accCount += 1\n",
    "    accDLoss += dLoss.data[0]\n",
    "    \n",
    "    # update image\n",
    "    blurred = Variable(blurredImages[bunch])\n",
    "    b = ((blurred.data.shape[2] - out.data.shape[2])/2, \n",
    "        (blurred.data.shape[3] - out.data.shape[3])/2)\n",
    "    imageOptimizers[bunch].zero_grad()\n",
    "    \n",
    "    genLoss = dCriterion(discriminator(out),  Variable(torch.ones(sharp.data.shape[0])).cuda())\n",
    "    recLoss = imgCriterion(out, blurred[:,:,b[0]:-b[0],b[1]:-b[1]])\n",
    "    imgLoss = recLoss + 0.0005*genLoss + 0.0005*dd\n",
    "    imgLoss.backward()\n",
    "    imageOptimizers[bunch].step()\n",
    "    deblurNets[bunch].constrain()\n",
    "\n",
    "    #blurred = Variable(blurredImages[bunch])\n",
    "    #imageOptimizers[bunch].zero_grad()\n",
    "    #imgLoss = imgCriterion(out, blurred[:,:,b[0]:-b[0],b[1]:-b[1]]) + 0.00001*dd\n",
    "    #imgLoss.backward()\n",
    "    #imageOptimizers[bunch].step()\n",
    "    #deblurNets[bunch].constrain()\n",
    "    accRecLoss += recLoss.data[0]\n",
    "    accGenLoss += genLoss.data[0]\n",
    "    \n",
    "    if (i % 1000) == 0:\n",
    "        print(accDLoss / accCount, accRecLoss / accCount, accGenLoss / accCount)\n",
    "        accDLoss = 0\n",
    "        accRecLoss = 0\n",
    "        accGenLoss = 0\n",
    "        accCount = 0\n",
    "        \n",
    "        fig = plt.figure(figsize=(14, 10), dpi=80, facecolor='w', edgecolor='k')\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.imshow(collage(originalImages[bunch].cpu().numpy()[0:4,::-1, :, :]))\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.imshow(collage(deblurNets[bunch].images.data[0:4].cpu().numpy()[:,::-1,:,:]))\n",
    "        plt.draw()\n",
    "        plt.show()    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred, sharp, psf, fid = getData(dataSource, 1, 512, 0.02)\n",
    "\n",
    "fig = plt.figure(figsize=(14, 10), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(sharp.data.cpu().numpy().transpose(0, 2, 3, 1)[0][:,:,::-1])\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(blurred.data.cpu().numpy().transpose(0, 2, 3, 1)[0][:,:,::-1])\n",
    "        \n",
    "        \n",
    "plt.draw()\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = DeblurClassic(blurred.data, psf.data)\n",
    "net.cuda()\n",
    "net = DeblurClassic(blurred.data, psf.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "net.cuda()\n",
    "\n",
    "blurred = blurred.cuda()\n",
    "psf = psf.cuda()\n",
    "\n",
    "out, dd = net()\n",
    "b = ((blurred.data.shape[2] - out.data.shape[2])/2, \n",
    "      (blurred.data.shape[3] - out.data.shape[3])/2)\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.2)\n",
    "#optimizer = torch.optim.SGD(net.parameters(), lr=200)\n",
    "#optimizer = torch.optim.LBFGS(net.parameters(), lr=1.8, max_iter=100, \n",
    "#                 tolerance_grad=1e-8, tolerance_change=1e-15,)\n",
    "\n",
    "\n",
    "for i in range(101):\n",
    "    \n",
    "    net.constrain()\n",
    "    def lossEvaluator():\n",
    "        optimizer.zero_grad()\n",
    "        out, dd = net()\n",
    "        loss = criterion(out, blurred[:,:,b[0]:-b[0],b[1]:-b[1]]) + 0.0000005*dd\n",
    "        loss.backward()\n",
    "        return loss\n",
    "    loss = optimizer.step(lossEvaluator)\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        net.constrain()\n",
    "        print(loss)\n",
    "        fig = plt.figure(figsize=(14, 10), dpi=80, facecolor='w', edgecolor='k')\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.imshow(sharp.data.cpu().numpy().transpose(0, 2, 3, 1)[0][:,:,::-1])\n",
    "        #plt.imshow(out.data.cpu().numpy().transpose(0, 2, 3, 1)[0][:,:,::-1])\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.imshow(net.image.data.cpu().numpy().transpose(0, 2, 3, 1)[0][:,:,::-1])\n",
    "        plt.draw()\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "\n",
    "out, dd = net()\n",
    "plt.imshow(out.data.cpu().numpy().transpose(0, 2, 3, 1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Variable(torch.Tensor(2)).max(Variable(torch.Tensor(1)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
